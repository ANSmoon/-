{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2841f96b-3a91-4cce-a806-7f83a0152b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#결과 이미지 저장할 폴더, 일정시간 이후에 삭제됨 T.T\n",
    "import os\n",
    "if not os.path.exists(\"./gan_images\"):\n",
    "    os.makedirs(\"./gan_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be61eabc-41c2-45e1-8d92-74a2a44b3898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6272)              633472    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 6272)             25088     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        204864    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 1)         1601      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 865,281\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#생성 모델\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2))) \n",
    "#128*7*7 : 출력 뉴런의 수, input_dim : 입력 뉴런의 수(입력의 차원), LeakyReLU() : x(x>=0), 0.2*x(x<0)\n",
    "generator.add(BatchNormalization()) #배치 정규화\n",
    "generator.add(Reshape((7, 7, 128))) #출력 뉴런의 수를 맞춰서 UpSampling후에 conv2D에 전달\n",
    "generator.add(UpSampling2D()) #입력 이미지의 크기 2배 확장\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same')) #64 필터의 갯수\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "#generator.compilie....XX...\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc3739e-89e2-42b1-8a16-dafbb47fb02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#판별 모델(실제 생성 모델을 위한 학습은 실시하지 않음)\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\")) #28*28 1channel\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam') #trainable = True.\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5deeb8c3-5320-4215-be95-434aff9ffa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 28, 28, 1)         865281    \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 1)                 212865    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,078,146\n",
      "Trainable params: 852,609\n",
      "Non-trainable params: 225,537\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.trainable = False #판별 후 자신이 학습하지 않도록 학습 기능을 OFF시킴. \n",
    "#생성 모듈과 판별 모델의 GAN 생성\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput)) \n",
    "gan = Model(ginput, dis_output) #ginput과 dis_output을 이용한 GAN생성\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462ec72d-f6be-4a5d-ab52-558761e6cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "\n",
    "  # MNIST 데이터 불러오기\n",
    "\n",
    "  (X_train, _), (_, _) = mnist.load_data()  # 테스트과정 불필요, 입력 이미지만 사용\n",
    "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_train = (X_train - 127.5) / 127.5  # 픽셀값 0 ~ 255 => -1 ~ 1 값 변경\n",
    "\n",
    "  true = np.ones((batch_size, 1))\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "          # 실제 데이터 판별 모듈에 입력\n",
    "          idx = np.random.randint(0, X_train.shape[0], batch_size) # 0 ~ X_train.shape[0], batch_size만큼 반복\n",
    "          imgs = X_train[idx]\n",
    "          d_loss_real = discriminator.train_on_batch(imgs, true) #판별 시작, 학습 실시\n",
    "\n",
    "          #가상 이미지 판별 모듈에 입력\n",
    "          noise = np.random.normal(0, 1, (batch_size, 100)) #batch_size만큼 100열 선출\n",
    "          gen_imgs = generator.predict(noise)\n",
    "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "          #판별 모듈와 생성 모듈의 오차를 계산\n",
    "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) #오차 계산\n",
    "          g_loss = gan.train_on_batch(noise, true) #noise를 1로 라벨링\n",
    "\n",
    "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 이부분은 중간 과정을 이미지로 저장해 주는 부분입니다. \n",
    "          if i % saving_interval == 0:\n",
    "              noise = np.random.normal(0, 1, (25, 100))\n",
    "              gen_imgs = generator.predict(noise)\n",
    "\n",
    "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "              fig, axs = plt.subplots(5, 5)\n",
    "              count = 0\n",
    "              for j in range(5):\n",
    "                  for k in range(5):\n",
    "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                      axs[j, k].axis('off')\n",
    "                      count += 1\n",
    "              fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625c38b-52e2-41c7-b151-0e08d9d87e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
